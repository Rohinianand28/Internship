{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059dd654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\programdata\\anaconda3\\lib\\site-packages (4.9.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: outcome in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62a091d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f28d0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bba7eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Windows\\Desktop\\New folder\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c15acc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the naukri page on automated chrome browser\n",
    "driver.get(\"http://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc2c75d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering designation and Location as required in the question number 1\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af498a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5e2465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aff49303",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "644e0553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "#scraping job location from the given page \n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#scraping company name from the given page\n",
    "companyname_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in companyname_tags[0:10]:\n",
    "    companyname=i.text\n",
    "    company_name.append(companyname)\n",
    "\n",
    "#scraping job Experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b4e253a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#Checking the Lenght\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64d99bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Comapany Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - IIT/BITS/Startups</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - IIT/BITS/Startups</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Siemens</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Banking Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, G...</td>\n",
       "      <td>Coforge</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Dpdzero</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Title  \\\n",
       "0                      Data Analyst   \n",
       "1                      Data Analyst   \n",
       "2  Data Analyst - IIT/BITS/Startups   \n",
       "3            Data Analyst - FinTech   \n",
       "4            Data Analyst - FinTech   \n",
       "5            Data Analyst - FinTech   \n",
       "6  Data Analyst - IIT/BITS/Startups   \n",
       "7                      Data Analyst   \n",
       "8              Banking Data Analyst   \n",
       "9                      Data Analyst   \n",
       "\n",
       "                                            Location Comapany Name Experience  \n",
       "0                                Bangalore/Bengaluru           ANZ    6-9 Yrs  \n",
       "1                                Bangalore/Bengaluru           ANZ   6-10 Yrs  \n",
       "2                                Bangalore/Bengaluru  AVE Promagne    1-5 Yrs  \n",
       "3  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...  Primo Hiring    1-2 Yrs  \n",
       "4  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...  Primo Hiring    1-2 Yrs  \n",
       "5  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...  Primo Hiring    1-2 Yrs  \n",
       "6                                Bangalore/Bengaluru  AVE Promagne    1-5 Yrs  \n",
       "7                                Bangalore/Bengaluru       Siemens    4-6 Yrs  \n",
       "8  Bangalore/Bengaluru, Hyderabad/Secunderabad, G...       Coforge   5-10 Yrs  \n",
       "9                                Bangalore/Bengaluru       Dpdzero    1-3 Yrs  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the Data Frame.\n",
    "data_frame1=pd.DataFrame({'Title':job_title, 'Location':job_location, 'Comapany Name':company_name, 'Experience':experience_required})\n",
    "data_frame1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6cb06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2\n",
    "\n",
    "#Driver is already connected in the Q1, so not connecting again in Q2.\n",
    "#Already naukri page is opend in automated chrome browser in Q1 so avoiding the same step in Q2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39d83804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering designation and Location as required in the question number 2\n",
    "\n",
    "designation_1=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation_1.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57166ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_1=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location_1.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16aa6ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03a18b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "job_title_1=[]\n",
    "job_location_1=[]\n",
    "company_name_1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6af605cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from the given page\n",
    "title_tags_1=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags_1[0:10]:\n",
    "    titles=i.text\n",
    "    job_title_1.append(titles)\n",
    "\n",
    "#scraping job location from the given page \n",
    "location_tags_1=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags_1[0:10]:\n",
    "    locations=i.text\n",
    "    job_location_1.append(locations)\n",
    "    \n",
    "#scraping company name from the given page\n",
    "companyname_tags_1=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in companyname_tags_1[0:10]:\n",
    "    companynames=i.text\n",
    "    company_name_1.append(companynames)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e30e62cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "#Checking the Lenght\n",
    "print(len(job_title_1),len(job_location_1),len(company_name_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "806bb6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Comapany Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist_NLP</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune, Chennai, Gu...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine Learning (AI) Architect</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>Persistent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist- Bangalore</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Trigent Software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Science Analyst - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Science Analyst Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Analytics Specialist - Artificial Intelligence...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                                 Data Scientist_NLP   \n",
       "2                    Machine Learning (AI) Architect   \n",
       "3                               Data Science Analyst   \n",
       "4                                     Data Scientist   \n",
       "5                          Data Scientist- Bangalore   \n",
       "6                Data Science Analyst - Data Science   \n",
       "7                  Data Science Analyst Data Science   \n",
       "8  Analytics Specialist - Artificial Intelligence...   \n",
       "9                              Senior Data Scientist   \n",
       "\n",
       "                                            Location      Comapany Name  \n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...          Accenture  \n",
       "1  Bangalore/Bengaluru, Mumbai, Pune, Chennai, Gu...  Fractal Analytics  \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...         Persistent  \n",
       "3                                Bangalore/Bengaluru          Accenture  \n",
       "4                                Bangalore/Bengaluru                IBM  \n",
       "5                                Bangalore/Bengaluru   Trigent Software  \n",
       "6                                Bangalore/Bengaluru          Accenture  \n",
       "7                                Bangalore/Bengaluru          Accenture  \n",
       "8                                Bangalore/Bengaluru          Accenture  \n",
       "9                                Bangalore/Bengaluru            Walmart  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the Data Frame.\n",
    "data_frame2=pd.DataFrame({'Title':job_title_1, 'Location':job_location_1, 'Comapany Name':company_name_1})\n",
    "data_frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5482894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "448a5575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Windows\\Desktop\\New folder\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16fb24bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the naukri page on automated chrome browser\n",
    "driver.get(\"http://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d889ad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering designation as required in the question number 3\n",
    "designation_2=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation_2.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e8f776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click search\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f6469d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the location filter by checking the respective box\n",
    "location_filter=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[5]/div[2]/div[2]/label/p/span[1]\")\n",
    "location_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee69e0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the salary filter by checking the respective box\n",
    "salary_filter=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/p/span[1]\")\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3660c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create empty list\n",
    "job_title_2=[]\n",
    "job_location_2=[]\n",
    "company_name_2=[]\n",
    "experience_required_2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "517c1fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from the given page\n",
    "title_tags_2=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags_2[0:10]:\n",
    "    title_2=i.text\n",
    "    job_title_2.append(title_2)\n",
    "\n",
    "#scraping job location from the given page \n",
    "location_tags_2=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags_2[0:10]:\n",
    "    location_2=i.text\n",
    "    job_location_2.append(location_2)\n",
    "    \n",
    "#scraping company name from the given page\n",
    "companyname_tags_2=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in companyname_tags_2[0:10]:\n",
    "    companyname_2=i.text\n",
    "    company_name_2.append(companyname_2)\n",
    "\n",
    "#scraping job Experience from the given page\n",
    "experience_tags_2=driver.find_elements(By.XPATH,'//div[@class=\"ellipsis job-description\"]')\n",
    "for i in experience_tags_2[0:10]:\n",
    "    experience_2=i.text\n",
    "    experience_required_2.append(experience_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4dda821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#Checking the Lenght\n",
    "print(len(job_title_2),len(job_location_2),len(company_name_2),len(experience_required_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "57ebff5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Comapany Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>Experience : 0 to 2 years. Experience / Strong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Blackbuck</td>\n",
       "      <td>Some of the problem areas are Insights across ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>You will collaborate with the brightest techni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, United States (USA), Bulgaria</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>Four-year college or university degree with fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - II (Contract)</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Netomi</td>\n",
       "      <td>3+ years of experience as a data scientist, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Gujarat Fluorochemicals</td>\n",
       "      <td>Functional Skills Required - Strong problem so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Research Scientist - Bioinformatics</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Biopeople India</td>\n",
       "      <td>Experience in molecular biology and associated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - I</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Netomi</td>\n",
       "      <td>Design and implement machine learning algorith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Profit By Outsourcing</td>\n",
       "      <td>2 years of relevant Machine learning experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Assistant Manager - Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Fidelity International</td>\n",
       "      <td>Graduation (must), preferably in Engineering, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title  \\\n",
       "0                Junior Data Scientist   \n",
       "1                       Data Scientist   \n",
       "2                       Data Scientist   \n",
       "3                Junior Data Scientist   \n",
       "4       Data Scientist - II (Contract)   \n",
       "5                       Data Scientist   \n",
       "6  Research Scientist - Bioinformatics   \n",
       "7                   Data Scientist - I   \n",
       "8            Machine Learning Engineer   \n",
       "9   Assistant Manager - Data Scientist   \n",
       "\n",
       "                                            Location            Comapany Name  \\\n",
       "0  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...                 Analytos   \n",
       "1              Gurgaon/Gurugram, Bangalore/Bengaluru                Blackbuck   \n",
       "2  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...                 Analytos   \n",
       "3    Gurgaon/Gurugram, United States (USA), Bulgaria                   Adidas   \n",
       "4                                   Gurgaon/Gurugram                   Netomi   \n",
       "5                                              Noida  Gujarat Fluorochemicals   \n",
       "6                                   Gurgaon/Gurugram          Biopeople India   \n",
       "7                                   Gurgaon/Gurugram                   Netomi   \n",
       "8                                              Noida    Profit By Outsourcing   \n",
       "9                                   Gurgaon/Gurugram   Fidelity International   \n",
       "\n",
       "                                          Experience  \n",
       "0  Experience : 0 to 2 years. Experience / Strong...  \n",
       "1  Some of the problem areas are Insights across ...  \n",
       "2  You will collaborate with the brightest techni...  \n",
       "3  Four-year college or university degree with fo...  \n",
       "4  3+ years of experience as a data scientist, pr...  \n",
       "5  Functional Skills Required - Strong problem so...  \n",
       "6  Experience in molecular biology and associated...  \n",
       "7  Design and implement machine learning algorith...  \n",
       "8  2 years of relevant Machine learning experienc...  \n",
       "9  Graduation (must), preferably in Engineering, ...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the Data Frame.\n",
    "data_frame3=pd.DataFrame({'Title':job_title_2, 'Location':job_location_2, 'Comapany Name':company_name_2, 'Experience':experience_required_2})\n",
    "data_frame3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd2cbcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "127da63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the flipkart page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e62f7afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering ‚Äúsunglasses‚Äù in the search field\n",
    "find=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "find.send_keys('Sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "47bde22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click the search icon\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f1684269",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "Brand_description=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4c6d90db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping brand name \n",
    "brand_name=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_name[0:100]:\n",
    "    brandname=i.text\n",
    "    Brand.append(brandname)\n",
    "    \n",
    "    \n",
    "# Scrapping brand description   \n",
    "    \n",
    "brand_description=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in brand_description[0:100]:\n",
    "    bd=i.text\n",
    "    Brand_description.append(bd)\n",
    "    \n",
    "    \n",
    "# Scrapping price on first page\n",
    "\n",
    "pri=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in pri[0:100]:\n",
    "    p=i.text\n",
    "    price.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "94a8720e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 114 120\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Brand_description),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "edb44d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brande</th>\n",
       "      <th>Brande Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Retro Squ...</td>\n",
       "      <td>‚Çπ849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (50)</td>\n",
       "      <td>‚Çπ789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (53)</td>\n",
       "      <td>‚Çπ149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Cat-eye, Retro Square, Oval, Rou...</td>\n",
       "      <td>‚Çπ109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>Polarized, UV Protection Retro Square Sunglass...</td>\n",
       "      <td>‚Çπ149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>‚Çπ949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Shield Sunglasses (Free Size)</td>\n",
       "      <td>‚Çπ99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>Polarized, UV Protection Rectangular Sunglasse...</td>\n",
       "      <td>‚Çπ249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>‚Çπ169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Sports Sunglasses (65)</td>\n",
       "      <td>‚Çπ879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brande                                 Brande Description Price\n",
       "0   VINCENT CHASE  by Lenskart Polarized, UV Protection Retro Squ...  ‚Çπ849\n",
       "1   VINCENT CHASE     Polarized, UV Protection Round Sunglasses (50)  ‚Çπ789\n",
       "2       Elligator             UV Protection Wayfarer Sunglasses (53)  ‚Çπ149\n",
       "3       Elligator  UV Protection Cat-eye, Retro Square, Oval, Rou...  ‚Çπ109\n",
       "4       Elligator  Polarized, UV Protection Retro Square Sunglass...  ‚Çπ149\n",
       "..            ...                                                ...   ...\n",
       "95  VINCENT CHASE  Gradient, UV Protection Wayfarer Sunglasses (F...  ‚Çπ949\n",
       "96          NuVew        UV Protection Shield Sunglasses (Free Size)   ‚Çπ99\n",
       "97      Elligator  Polarized, UV Protection Rectangular Sunglasse...  ‚Çπ249\n",
       "98           SRPM      UV Protection Wayfarer Sunglasses (Free Size)  ‚Çπ169\n",
       "99  VINCENT CHASE               UV Protection Sports Sunglasses (65)  ‚Çπ879\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the Data Frame.\n",
    "data_frame4=pd.DataFrame({'Brande':Brand[0:100], 'Brande Description':Brand_description[0:100], 'Price':price[0:100]})\n",
    "data_frame4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5524ecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5.Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb/product\u0002reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market place=FLIPKART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cbefe67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the flipkart page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ec6fa0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Entering ‚Äúiphone11‚Äù in the search field\n",
    "\n",
    "find_2=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "find_2.send_keys(\"iphone11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cabbc1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click the search icon\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a6c1b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening https://www.flipkart.com/apple-iphone-11-black-64-gb/product\u0002reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market place=FLIPKART\n",
    "click= driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div[1]/div[2]/div[5]/div/div/div/a/div[2]/div[1]/div[1]\")\n",
    "click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d7cd2a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list \n",
    "Rating=[]\n",
    "Review_summary=[]\n",
    "Full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "45c5578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Rating \n",
    "rating=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in rating[0:100]:\n",
    "    R=i.text\n",
    "    Rating.append(R)\n",
    "\n",
    "    \n",
    "# Scrapping Review summary   \n",
    "reviwsummary=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "for i in reviwsummary[0:100]:\n",
    "    rv=i.text\n",
    "    Review_summary.append(rv)\n",
    "   \n",
    "# scrapping Full review   \n",
    "review=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "for i in review[0:100]:\n",
    "    rvs=i.text\n",
    "    Full_review.append(rvs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e6ca4301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 108 102\n"
     ]
    }
   ],
   "source": [
    "#checking the lenght of the lists\n",
    "print(len(Rating),len(Review_summary),len(Full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "90ada232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Good quality product</td>\n",
       "      <td>impressively Nice......\\nOne of the greatest i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Nice products thanks flkat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Good üëç phone ü§≥ lucky ‚ù§Ô∏èüòò</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Fast performance to previous iPhone x\\nGood ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Awesome product ‚ù§Ô∏è‚ù§Ô∏è\\nThank you Flipkart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4</td>\n",
       "      <td>Good quality product</td>\n",
       "      <td>impressively Nice......\\nOne of the greatest i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Nice products thanks flkat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Good üëç phone ü§≥ lucky ‚ù§Ô∏èüòò</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating        Review summary  \\\n",
       "0       4  Good quality product   \n",
       "1       5      Perfect product!   \n",
       "2       5        Simply awesome   \n",
       "3       5     Terrific purchase   \n",
       "4       5             Fabulous!   \n",
       "..    ...                   ...   \n",
       "95      5         Great product   \n",
       "96      4  Good quality product   \n",
       "97      5      Perfect product!   \n",
       "98      5        Simply awesome   \n",
       "99      5     Terrific purchase   \n",
       "\n",
       "                                          Full Review  \n",
       "0   impressively Nice......\\nOne of the greatest i...  \n",
       "1                          Nice products thanks flkat  \n",
       "2   Really satisfied with the Product I received.....  \n",
       "3                            Good üëç phone ü§≥ lucky ‚ù§Ô∏èüòò  \n",
       "4   Fast performance to previous iPhone x\\nGood ca...  \n",
       "..                                                ...  \n",
       "95           Awesome product ‚ù§Ô∏è‚ù§Ô∏è\\nThank you Flipkart  \n",
       "96  impressively Nice......\\nOne of the greatest i...  \n",
       "97                         Nice products thanks flkat  \n",
       "98  Really satisfied with the Product I received.....  \n",
       "99                           Good üëç phone ü§≥ lucky ‚ù§Ô∏èüòò  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the data frame.\n",
    "data_frame5=pd.DataFrame({'Rating':Rating[0:100], 'Review summary':Review_summary[0:100], 'Full Review':Full_review[0:100]})\n",
    "data_frame5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "72f494a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. : Scrape data for first 100 sneakers you find when you visit flipkart.com and search for ‚Äúsneakers‚Äù in the search field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "017d96b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the flipkart page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9c5b532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering ‚Äúsneakers‚Äù in the search field\n",
    "find=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "find.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "42ea2ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click the search icon\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "65b63bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand_1=[]\n",
    "Product_description=[]\n",
    "price_1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4857640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping brand name \n",
    "brand_name_2=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_name_2[0:100]:\n",
    "    brandnames=i.text\n",
    "    Brand_1.append(brandnames)\n",
    "    \n",
    "    \n",
    "# Scrapping product description   \n",
    "    \n",
    "product_description=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in product_description[0:100]:\n",
    "    bd=i.text\n",
    "    Product_description.append(bd)\n",
    "    \n",
    "    \n",
    "# Scrapping price \n",
    "\n",
    "pric=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in pric[0:100]:\n",
    "    pr=i.text\n",
    "    price_1.append(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3cae2682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand_1),len(Product_description),len(price_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b91ce6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brande</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K- FOOTLANCE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>Casual Sneakers White Shoes For Girls And Snea...</td>\n",
       "      <td>‚Çπ449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Synthetic| Lightweight| Premiun| Comfort| Summ...</td>\n",
       "      <td>‚Çπ299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>‚Çπ499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Mesh |Lightweight|Comfort|Summer|Trendy|Walkin...</td>\n",
       "      <td>‚Çπ299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Premium Sports Shoes For Men Pack Of 2 Sneaker...</td>\n",
       "      <td>‚Çπ499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Shoes Sneakers For Men</td>\n",
       "      <td>‚Çπ249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Lightweight,Comfort,Summer,Trendy,Walking,Outd...</td>\n",
       "      <td>‚Çπ299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Brande                                Product Description Price\n",
       "0       RapidBox                                   Sneakers For Men  ‚Çπ579\n",
       "1   K- FOOTLANCE                                   Sneakers For Men  ‚Çπ399\n",
       "2         Layasa  Casual Sneakers White Shoes For Girls And Snea...  ‚Çπ449\n",
       "3           aadi  Synthetic| Lightweight| Premiun| Comfort| Summ...  ‚Çπ299\n",
       "4          BIRDE      Combo Pack Of 2 Casual Shoes Sneakers For Men  ‚Çπ499\n",
       "..           ...                                                ...   ...\n",
       "95        Labbin                                   Sneakers For Men  ‚Çπ379\n",
       "96          aadi  Mesh |Lightweight|Comfort|Summer|Trendy|Walkin...  ‚Çπ299\n",
       "97         BIRDE  Premium Sports Shoes For Men Pack Of 2 Sneaker...  ‚Çπ499\n",
       "98        BRUTON               Modern Trendy Shoes Sneakers For Men  ‚Çπ249\n",
       "99          aadi  Lightweight,Comfort,Summer,Trendy,Walking,Outd...  ‚Çπ299\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the Data Frame.\n",
    "data_frame6=pd.DataFrame({'Brande':Brand_1[0:100], 'Product Description':Product_description[0:100], 'Price':price_1[0:100]})\n",
    "data_frame6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7fda4632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7.Go to webpage https://www.amazon.in/ Enter ‚ÄúLaptop‚Äù in the search field and then click the search icon. Then set CPU Type filter to ‚ÄúIntel Core i7‚Äù as shown in the below image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7362e047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the amazon page on automated chrome browser\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f94bd9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter Laption in the search \n",
    "search_g= driver.find_element(By.XPATH,\"//input[@type='text']\")\n",
    "search_g.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ccb7383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on search bar\n",
    "search_btn=driver.find_element(By.XPATH,\"//input[@id='nav-search-submit-button']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c860bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##apply the CPU filter by checking the respective box\n",
    "location_filter_cpu=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[7]/span[13]/li/span/a/span\")\n",
    "location_filter_cpu.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d2b786eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Empty list\n",
    "Title_3=[]\n",
    "Ratings_3=[]\n",
    "Price_3=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "13e69519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Title  \n",
    "Title3=driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in Title3[0:10]:\n",
    "    title=i.text\n",
    "    Title_3.append(title)\n",
    "    \n",
    "# Scrapping Rating \n",
    "ratingss=driver.find_elements(By.XPATH,'//div[@class=\"a-row a-spacing-medium\"]')\n",
    "for i in ratingss[0:10]:\n",
    "    Rtng=i.text\n",
    "    Ratings_3.append(Rtng)\n",
    "    \n",
    "# Scrapping price \n",
    "\n",
    "pricss=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in pricss[0:10]:\n",
    "    prc=i.text\n",
    "    Price_3.append(prc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c920fffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 16 40\n"
     ]
    }
   ],
   "source": [
    "#Checking the lenght\n",
    "print(len(Title_3),len(Ratings_3),len(Price_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f2ea4fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS TUF Gaming F15 (2022), 15.6\"(39.62 cms) F...</td>\n",
       "      <td></td>\n",
       "      <td>94,989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo ThinkPad E14 Intel Core i7 12th Gen 14\"...</td>\n",
       "      <td></td>\n",
       "      <td>98,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP Envy x360 12th Gen Intel Core i7-13.3 inch(...</td>\n",
       "      <td></td>\n",
       "      <td>1,02,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Samsung Galaxy Book2 (NP750) Intel 12th Gen co...</td>\n",
       "      <td></td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LG Gram16 Intel EVO-[12th Gen Core i7/Win11/16...</td>\n",
       "      <td></td>\n",
       "      <td>99,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Victus Gaming Latest 12th Gen Intel Core i7...</td>\n",
       "      <td></td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS Zenbook Pro 14 Duo OLED (2022) Dual Scree...</td>\n",
       "      <td></td>\n",
       "      <td>1,24,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Acer Predator Helios Neo 16 Gaming Laptop 13th...</td>\n",
       "      <td></td>\n",
       "      <td>1,29,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td></td>\n",
       "      <td>88,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Envy x360 for Creators 12th Gen Intel Core ...</td>\n",
       "      <td></td>\n",
       "      <td>97,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Ratings     Price\n",
       "0  ASUS TUF Gaming F15 (2022), 15.6\"(39.62 cms) F...            94,989\n",
       "1  Lenovo ThinkPad E14 Intel Core i7 12th Gen 14\"...            98,990\n",
       "2  HP Envy x360 12th Gen Intel Core i7-13.3 inch(...          1,02,990\n",
       "3  Samsung Galaxy Book2 (NP750) Intel 12th Gen co...            79,990\n",
       "4  LG Gram16 Intel EVO-[12th Gen Core i7/Win11/16...            99,990\n",
       "5  HP Victus Gaming Latest 12th Gen Intel Core i7...            79,990\n",
       "6  ASUS Zenbook Pro 14 Duo OLED (2022) Dual Scree...          1,24,990\n",
       "7  Acer Predator Helios Neo 16 Gaming Laptop 13th...          1,29,990\n",
       "8  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...            88,990\n",
       "9  HP Envy x360 for Creators 12th Gen Intel Core ...            97,990"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the Data Frame.\n",
    "data_frame6=pd.DataFrame({'Title':Title_3[0:10], 'Ratings':Ratings_3[0:10], 'Price':Price_3[0:10]})\n",
    "data_frame6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "aa0a7f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9. Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7bae1829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 First get the webpagehttps://www.jagranjosh.com/\n",
    "driver.get(\"https://www.jagranjosh.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "d731407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 click on the GK option\n",
    "click_on_gk=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div/div[1]/div/div[5]/div/div[1]/header/div[3]/ul/li[3]/a\")\n",
    "click_on_gk.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "7b69b6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3  click on the List of all Prime Ministers of India\n",
    "prime_ministers=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a\")\n",
    "prime_ministers.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "70b97dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list\n",
    "Name=[]\n",
    "Born_Dead = [] \n",
    "Term_of_office=[] \n",
    "Remarks=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "7e638de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping name\n",
    "\n",
    "primeminister=driver.find_elements(By.XPATH,'/html/body/div/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[2]/table/tbody/tr[2]/td[2]/p')\n",
    "for i in primeminister:\n",
    "    names=i.text\n",
    "    Name.append(names)\n",
    "    \n",
    "# Scrapping Born_Dead\n",
    "\n",
    "dates=driver.find_elements(By.XPATH,'/html/body/div/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[2]/table/tbody/tr[2]/td[3]/p')\n",
    "for i in dates:\n",
    "    dt=i.text\n",
    "    Born_Dead.append(dt)\n",
    "    \n",
    "# Scrapping Term_of_office\n",
    "termofoffice=driver.find_elements(By.XPATH,'/html/body/div/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[2]/table/tbody/tr[2]/td[4]/p[1]/span')\n",
    "for i in termofoffice:\n",
    "    trms=i.text\n",
    "    Term_of_office.append(trms)\n",
    "    \n",
    "# Scrapping Remarks\n",
    "\n",
    "remark=driver.find_elements(By.XPATH,'/html/body/div/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[2]/table/tbody/tr[2]/td[5]/p')\n",
    "for i in remark:\n",
    "    rmk=i.text\n",
    "    Remarks.append(rmk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "cee64277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 3 3\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(Born_Dead),len(Term_of_office),len(Remarks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "469a587a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Born Dead</th>\n",
       "      <th>Term of office</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>(1889‚Äì1964)</td>\n",
       "      <td>15 August 1947 to 27 May 1964\\n16 years, 286 days</td>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>(1889‚Äì1964)</td>\n",
       "      <td>15 August 1947 to 27 May 1964</td>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>(1889‚Äì1964)</td>\n",
       "      <td>15 August 1947 to 27 May 1964</td>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name    Born Dead  \\\n",
       "0  Jawahar Lal Nehru  (1889‚Äì1964)   \n",
       "1  Jawahar Lal Nehru  (1889‚Äì1964)   \n",
       "2  Jawahar Lal Nehru  (1889‚Äì1964)   \n",
       "\n",
       "                                      Term of office  \\\n",
       "0  15 August 1947 to 27 May 1964\\n16 years, 286 days   \n",
       "1                      15 August 1947 to 27 May 1964   \n",
       "2                      15 August 1947 to 27 May 1964   \n",
       "\n",
       "                                             Remarks  \n",
       "0  The first prime minister of India and the long...  \n",
       "1  The first prime minister of India and the long...  \n",
       "2  The first prime minister of India and the long...  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the Data Frame.\n",
    "data_frame9=pd.DataFrame({'Name':Name, 'Born Dead':Born_Dead, 'Term of office':Term_of_office,'Remarks':Remarks})\n",
    "data_frame9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c811ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.10.: Write a python program to display list of 50 Most expensive cars in the world (i.e. Car name and Price) from https://www.motor1.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "1ff8dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. First get the webpage https://www.motor1.com/\n",
    "driver.get(\"https://www.motor1.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ffe71732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Then You have to click on the List option from Dropdown menu on leftside.\n",
    "click=driver.find_element(By.XPATH,\"/html/body/div[4]/div[1]/div[3]/ul/li[6]/ul/li[1]/a\")\n",
    "click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "3a620d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Then click on 50 most expensive carsin the world..\n",
    "click_2=driver.find_element(By.XPATH,\"/html/body/div[3]/div[8]/div[1]/div[1]/div/div/div[7]/div/div[1]/h3/a\")\n",
    "click_2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "1788d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create empty list\n",
    "Car_name =[]\n",
    "Price_10=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "11f5b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Remarks\n",
    "\n",
    "carname=driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]')\n",
    "for i in carname:\n",
    "    namesofcar=i.text\n",
    "    Car_name.append(namesofcar)\n",
    "    \n",
    "# Scrapping Remarks\n",
    "\n",
    "price_10=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[4]/strong')\n",
    "for i in price_10:\n",
    "    prics=i.text\n",
    "    Price_10.append(prics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "a4927e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 1\n"
     ]
    }
   ],
   "source": [
    "print(len(Car_name),len(Price_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f033f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8. Write a python program to scrape data for Top 1000 Quotes of All Time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "664987d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Windows\\Desktop\\New folder\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ba21932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the azquotes page on automated chrome browser\n",
    "driver.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "76208586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "Quote=[]\n",
    "Author=[]\n",
    "Type_Of_Quotes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "ad7457e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Quote\n",
    "for page in range(0,10):\n",
    "    \n",
    "    quote=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for i in quote:\n",
    "        quo=i.text\n",
    "        Quote.append(quo)\n",
    "    next_page=driver.find_elements(By.XPATH,'//li[@class=\"next\"]')\n",
    "    \n",
    "# Scrapping Author\n",
    "for page in range(0,10):\n",
    "    author=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for i in author:\n",
    "        aut=i.text\n",
    "        Author.append(aut)\n",
    "    next_page=driver.find_elements(By.XPATH,'//li[@class=\"next\"]')\n",
    "    \n",
    "# Scrapping Type Of Quotes\n",
    "\n",
    "for page in range(0,10):\n",
    "    typeofquotes=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for i in typeofquotes:\n",
    "        tq=i.text\n",
    "        Type_Of_Quotes.append(tq)\n",
    "    next_page=driver.find_elements(By.XPATH,'//li[@class=\"next\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "e8e48703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(Quote),len(Author),len(Type_Of_Quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "35b3db81",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[251], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Creating the Data Frame.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data_frame8\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQuote\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mQuote\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAuthor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mAuthor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mType Of Quotes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mType_Of_Quotes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m data_frame8\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "#Creating the Data Frame.\n",
    "data_frame8=pd.DataFrame({'Quote':Quote[0:1000], 'Author':Author[0:1000], 'Type Of Quotes':Type_Of_Quotes[0:1000]})\n",
    "data_frame8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51b1309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
